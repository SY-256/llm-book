{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 固有表現認識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 固有表現認識とは？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy-alignments seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 3.98k/3.98k [00:00<00:00, 26.0MB/s]\n",
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset ner-wikipedia-dataset/default to /root/.cache/huggingface/datasets/llm-book___ner-wikipedia-dataset/default/0.0.0/184bcf9be66116e777f2f534436226d47348676c93ba20cca58933f1b2b3b782...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 4.04MB [00:00, 59.4MB/s]                  \n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ner-wikipedia-dataset downloaded and prepared to /root/.cache/huggingface/datasets/llm-book___ner-wikipedia-dataset/default/0.0.0/184bcf9be66116e777f2f534436226d47348676c93ba20cca58933f1b2b3b782. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 682.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# データセットを読み込む\n",
    "dataset = load_dataset(\"llm-book/ner-wikipedia-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['curid', 'text', 'entities'],\n",
      "        num_rows: 4274\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['curid', 'text', 'entities'],\n",
      "        num_rows: 534\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['curid', 'text', 'entities'],\n",
      "        num_rows: 535\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# データセットの形式と事例数を確認する\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'curid': '3638038',\n",
      "  'entities': [{'name': 'さくら学院', 'span': [0, 5], 'type': 'その他の組織名'},\n",
      "               {'name': 'Ciao Smiles', 'span': [6, 17], 'type': 'その他の組織名'}],\n",
      "  'text': 'さくら学院、Ciao Smilesのメンバー。'},\n",
      " {'curid': '1729527',\n",
      "  'entities': [{'name': 'レクレアティーボ・ウェルバ', 'span': [17, 30], 'type': 'その他の組織名'},\n",
      "               {'name': 'プリメーラ・ディビシオン', 'span': [32, 44], 'type': 'その他の組織名'}],\n",
      "  'text': '2008年10月5日、アウェーでのレクレアティーボ・ウェルバ戦でプリメーラ・ディビシオンでの初得点を決めた。'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# 訓練セットの最初の二つの事例を表示する\n",
    "pprint(list(dataset[\"train\"])[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットの分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>人名</th>\n",
       "      <td>2394</td>\n",
       "      <td>299</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>法人名</th>\n",
       "      <td>2006</td>\n",
       "      <td>231</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>地名</th>\n",
       "      <td>1769</td>\n",
       "      <td>184</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>政治的組織名</th>\n",
       "      <td>953</td>\n",
       "      <td>121</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>製品名</th>\n",
       "      <td>934</td>\n",
       "      <td>123</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>施設名</th>\n",
       "      <td>868</td>\n",
       "      <td>103</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>その他の組織名</th>\n",
       "      <td>852</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>イベント名</th>\n",
       "      <td>831</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>合計</th>\n",
       "      <td>10607</td>\n",
       "      <td>1245</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train  validation  test\n",
       "人名        2394         299   287\n",
       "法人名       2006         231   248\n",
       "地名        1769         184   204\n",
       "政治的組織名     953         121   106\n",
       "製品名        934         123   158\n",
       "施設名        868         103   137\n",
       "その他の組織名    852          99   100\n",
       "イベント名      831          85    93\n",
       "合計       10607        1245  1333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "def count_label_occurrences(dataset: Dataset) -> dict[str, int]:\n",
    "    \"\"\"固有表現タイプの出現回数をカウント\"\"\"\n",
    "    # 各事例から固有表現タイプを抽出したlistを作成する\n",
    "    entities = [\n",
    "        e[\"type\"] for data in dataset for e in data[\"entities\"]\n",
    "    ]\n",
    "    \n",
    "    # ラベルの表現回数が多い順に並べる\n",
    "    label_counts = dict(Counter(entities).most_common())\n",
    "    return label_counts\n",
    "    \n",
    "label_counts_dict = {}\n",
    "for split in dataset: # 各分割セットを処理する\n",
    "    label_counts_dict[split] = count_label_occurrences(dataset[split])\n",
    "# DataFrame形式で表示する\n",
    "df = pd.DataFrame(label_counts_dict)\n",
    "df.loc[\"合計\"] = df.sum()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### スパンの重なる固有表現の存在を判定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainにおけるスパンが重複する事例数:0\n",
      "validationにおけるスパンが重複する事例数:0\n",
      "testにおけるスパンが重複する事例数:0\n"
     ]
    }
   ],
   "source": [
    "def has_overlap(spans: list[tuple[int, int]]) -> int:\n",
    "    \"\"\"スパンの重なる固有表現の存在を判定\"\"\"\n",
    "    sorted_spans = sorted(spans, key=lambda x: x[0])\n",
    "    for i in range(1, len(sorted_spans)):\n",
    "        # 前のスパンの終了位置が現在のスパンの開始位置より大きい場合、\n",
    "        # 重なっているとする\n",
    "        if sorted_spans[i - 1][1] > sorted_spans[i][0]:\n",
    "            return 1\n",
    "    return 0\n",
    "    \n",
    "# 各分割セットでスパンの重なる固有表現がある事例数を数える\n",
    "overlap_count = 0\n",
    "for split in dataset: # 各分割セットを処理する\n",
    "    for data in dataset[split]: # 各事例を処理する\n",
    "        if data[\"entities\"]: # 固有表現の存在しない事例はスキップ\n",
    "            # スパンのみのlistを作成する\n",
    "            spans = [e[\"span\"] for e in data[\"entities\"]]\n",
    "            overlap_count += has_overlap(spans)\n",
    "    print(f\"{split}におけるスパンが重複する事例数:{overlap_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
