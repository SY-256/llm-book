{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 固有表現認識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 固有表現認識とは？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy-alignments seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration default\n",
      "Reusing dataset ner-wikipedia-dataset (/root/.cache/huggingface/datasets/llm-book___ner-wikipedia-dataset/default/0.0.0/184bcf9be66116e777f2f534436226d47348676c93ba20cca58933f1b2b3b782)\n",
      "100%|██████████| 3/3 [00:00<00:00, 213.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# データセットを読み込む\n",
    "dataset = load_dataset(\"llm-book/ner-wikipedia-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['curid', 'text', 'entities'],\n",
      "        num_rows: 4274\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['curid', 'text', 'entities'],\n",
      "        num_rows: 534\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['curid', 'text', 'entities'],\n",
      "        num_rows: 535\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# データセットの形式と事例数を確認する\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'curid': '3638038',\n",
      "  'entities': [{'name': 'さくら学院', 'span': [0, 5], 'type': 'その他の組織名'},\n",
      "               {'name': 'Ciao Smiles', 'span': [6, 17], 'type': 'その他の組織名'}],\n",
      "  'text': 'さくら学院、Ciao Smilesのメンバー。'},\n",
      " {'curid': '1729527',\n",
      "  'entities': [{'name': 'レクレアティーボ・ウェルバ', 'span': [17, 30], 'type': 'その他の組織名'},\n",
      "               {'name': 'プリメーラ・ディビシオン', 'span': [32, 44], 'type': 'その他の組織名'}],\n",
      "  'text': '2008年10月5日、アウェーでのレクレアティーボ・ウェルバ戦でプリメーラ・ディビシオンでの初得点を決めた。'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# 訓練セットの最初の二つの事例を表示する\n",
    "pprint(list(dataset[\"train\"])[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットの分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>人名</th>\n",
       "      <td>2394</td>\n",
       "      <td>299</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>法人名</th>\n",
       "      <td>2006</td>\n",
       "      <td>231</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>地名</th>\n",
       "      <td>1769</td>\n",
       "      <td>184</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>政治的組織名</th>\n",
       "      <td>953</td>\n",
       "      <td>121</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>製品名</th>\n",
       "      <td>934</td>\n",
       "      <td>123</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>施設名</th>\n",
       "      <td>868</td>\n",
       "      <td>103</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>その他の組織名</th>\n",
       "      <td>852</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>イベント名</th>\n",
       "      <td>831</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>合計</th>\n",
       "      <td>10607</td>\n",
       "      <td>1245</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train  validation  test\n",
       "人名        2394         299   287\n",
       "法人名       2006         231   248\n",
       "地名        1769         184   204\n",
       "政治的組織名     953         121   106\n",
       "製品名        934         123   158\n",
       "施設名        868         103   137\n",
       "その他の組織名    852          99   100\n",
       "イベント名      831          85    93\n",
       "合計       10607        1245  1333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "def count_label_occurrences(dataset: Dataset) -> dict[str, int]:\n",
    "    \"\"\"固有表現タイプの出現回数をカウント\"\"\"\n",
    "    # 各事例から固有表現タイプを抽出したlistを作成する\n",
    "    entities = [\n",
    "        e[\"type\"] for data in dataset for e in data[\"entities\"]\n",
    "    ]\n",
    "    \n",
    "    # ラベルの表現回数が多い順に並べる\n",
    "    label_counts = dict(Counter(entities).most_common())\n",
    "    return label_counts\n",
    "    \n",
    "label_counts_dict = {}\n",
    "for split in dataset: # 各分割セットを処理する\n",
    "    label_counts_dict[split] = count_label_occurrences(dataset[split])\n",
    "# DataFrame形式で表示する\n",
    "df = pd.DataFrame(label_counts_dict)\n",
    "df.loc[\"合計\"] = df.sum()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### スパンの重なる固有表現の存在を判定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainにおけるスパンが重複する事例数:0\n",
      "validationにおけるスパンが重複する事例数:0\n",
      "testにおけるスパンが重複する事例数:0\n"
     ]
    }
   ],
   "source": [
    "def has_overlap(spans: list[tuple[int, int]]) -> int:\n",
    "    \"\"\"スパンの重なる固有表現の存在を判定\"\"\"\n",
    "    sorted_spans = sorted(spans, key=lambda x: x[0])\n",
    "    for i in range(1, len(sorted_spans)):\n",
    "        # 前のスパンの終了位置が現在のスパンの開始位置より大きい場合、\n",
    "        # 重なっているとする\n",
    "        if sorted_spans[i - 1][1] > sorted_spans[i][0]:\n",
    "            return 1\n",
    "    return 0\n",
    "    \n",
    "# 各分割セットでスパンの重なる固有表現がある事例数を数える\n",
    "overlap_count = 0\n",
    "for split in dataset: # 各分割セットを処理する\n",
    "    for data in dataset[split]: # 各事例を処理する\n",
    "        if data[\"entities\"]: # 固有表現の存在しない事例はスキップ\n",
    "            # スパンのみのlistを作成する\n",
    "            spans = [e[\"span\"] for e in data[\"entities\"]]\n",
    "            overlap_count += has_overlap(spans)\n",
    "    print(f\"{split}におけるスパンが重複する事例数:{overlap_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テキストの正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正規化前: ＡＢＣABCａｂｃabcｱｲｳアイウ①②③123\n",
      "正規化後: ABCABCabcabcアイウアイウ123123\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "# テキストに対してUnicode正規化を行う\n",
    "text =  \"ＡＢＣABCａｂｃabcｱｲｳアイウ①②③123\"\n",
    "normalized_text = normalize(\"NFKC\", text)\n",
    "print(f\"正規化前: {text}\")\n",
    "print(f\"正規化後: {normalized_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正規化前: ㈱、3㌕、10℃\n",
      "正規化後: (株)、3キログラム、10°C\n"
     ]
    }
   ],
   "source": [
    "# 文字列の長さが変わる場合ある\n",
    "text = \"㈱、3㌕、10℃\"\n",
    "normalized_text = normalize(\"NFKC\", text)\n",
    "print(f\"正規化前: {text}\")\n",
    "print(f\"正規化後: {normalized_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正規化されていない事例数: 0\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, is_normalized\n",
    "\n",
    "count = 0\n",
    "for split in dataset: # 各分割セットを処理する\n",
    "    for data in dataset[split]: # 各事例を処理する\n",
    "        # テキストが正規化されていない事例をカウントする\n",
    "        if not is_normalized(\"NFKC\", data[\"text\"]):\n",
    "            count += 1\n",
    "print(f\"正規化されていない事例数: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テキストのトークナイゼーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "サブワード単位: さくら/学院/、/C/##ia/##o/Sm/##ile/##s/の/メンバー/。\n",
      "文単位: さ/く/ら/学/院/、/C/i/a/o/ /S/m/i/l/e/s/の/メ/ン/バ/ー/。\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# トークナイザを読み込み\n",
    "model_name = \"tohoku-nlp/bert-base-japanese-v3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# トークナイゼーションを行う\n",
    "subwords = \"/\".join(tokenizer.tokenize(dataset[\"train\"][0][\"text\"]))\n",
    "characters = \"/\".join(dataset[\"train\"][0][\"text\"])\n",
    "print(f\"サブワード単位: {subwords}\")\n",
    "print(f\"文単位: {characters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文字列とトークン列のアライメント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"さくら学院\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字のlist: ['さ', 'く', 'ら', '学', '院']\n",
      "トークンのlist: ['[CLS]', 'さくら', '学院', '[SEP]']\n",
      "文字に対するトークンの位置: [[1], [1], [1], [2], [2]]\n",
      "トークンに対する文字の位置: [[], [0, 1, 2], [3, 4], []]\n"
     ]
    }
   ],
   "source": [
    "from spacy_alignments.tokenizations import get_alignments\n",
    "\n",
    "# 文字列のlistを獲得する\n",
    "characters = list(text)\n",
    "# テキストを特殊トークンを含めたトークンのlistに変換する\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(text))\n",
    "# 文字のlistとトークンのlistのアライメントをとる\n",
    "char_to_token_indices, token_to_char_indices = get_alignments(characters, tokens)\n",
    "print(f\"文字のlist: {characters}\")\n",
    "print(f\"トークンのlist: {tokens}\")\n",
    "print(f\"文字に対するトークンの位置: {char_to_token_indices}\")\n",
    "print(f\"トークンに対する文字の位置: {token_to_char_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 系列ラベリングのためのラベル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"大谷翔平は岩手県水沢市出身\"\n",
    "entities = [\n",
    "    {\"name\": \"大谷翔平\", \"span\": [0,4], \"type\": \"人名\"},\n",
    "    {\"name\": \"岩手県水沢市\", \"span\": [5,11], \"type\": \"地名\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>位置</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>トークン列</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>大谷</td>\n",
       "      <td>翔</td>\n",
       "      <td>##平</td>\n",
       "      <td>は</td>\n",
       "      <td>岩手</td>\n",
       "      <td>県</td>\n",
       "      <td>水沢</td>\n",
       "      <td>市</td>\n",
       "      <td>出身</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ラベル列</th>\n",
       "      <td>-</td>\n",
       "      <td>B-人名</td>\n",
       "      <td>I-人名</td>\n",
       "      <td>I-人名</td>\n",
       "      <td>O</td>\n",
       "      <td>B-地名</td>\n",
       "      <td>I-地名</td>\n",
       "      <td>I-地名</td>\n",
       "      <td>I-地名</td>\n",
       "      <td>O</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "位置        0     1     2     3  4     5     6     7     8   9      10\n",
       "トークン列  [CLS]    大谷     翔   ##平  は    岩手     県    水沢     市  出身  [SEP]\n",
       "ラベル列       -  B-人名  I-人名  I-人名  O  B-地名  I-地名  I-地名  I-地名   O      -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "def output_tokens_and_labels(\n",
    "    text: str,\n",
    "    entities: list[dict[str, list[int] | str]],\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    ") -> tuple[list[str], list[str]]:\n",
    "    \"\"\"トークンのlistとラベルのlistを出力\"\"\"\n",
    "    # 文字列のlistとトークンのlistのアライメントをとる\n",
    "    characters = list(text)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(text))\n",
    "    char_to_token_indices, _ = get_alignments(characters, tokens)\n",
    "    \n",
    "    # \"O\"のラベルで初期化したラベルのlistを作成する\n",
    "    labels = [\"O\"] * len(tokens)\n",
    "    for entity in entities: # 各固有表現で処理する\n",
    "        entity_span, entity_type = entity[\"span\"], entity[\"type\"]\n",
    "        start = char_to_token_indices[entity_span[0]][0]\n",
    "        end = char_to_token_indices[entity_span[1]-1][0]\n",
    "        # 固有表現の開始トークンの位置に\"B-\"のラベルを設定する\n",
    "        labels[start] = f\"B-{entity_type}\"\n",
    "        # 固有表現の開始トークン以外の位置に\"I-\"のラベルを設定する\n",
    "        for idx in range(start + 1, end + 1):\n",
    "            labels[idx] = f\"I-{entity_type}\"\n",
    "    # 特殊トークンの位置にはラベルを設定しない\n",
    "    labels[0] = \"-\" # 開始\n",
    "    labels[-1] = \"-\" # 終了\n",
    "    return tokens, labels\n",
    "\n",
    "# トークンとラベルのlistを出力する\n",
    "tokens, labels = output_tokens_and_labels(text, entities, tokenizer)\n",
    "# DataFrameの形式で表示する\n",
    "df = pd.DataFrame({\"トークン列\": tokens, \"ラベル列\": labels})\n",
    "df.index.name = \"位置\"\n",
    "display(df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
