{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers[ja,sentencepice,torch] in /usr/local/lib/python3.10/dist-packages (4.21.2)\n",
      "\u001b[33mWARNING: transformers 4.21.2 does not provide the extra 'sentencepice'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepice,torch]) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepice,torch]) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepice,torch]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepice,torch]) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepice,torch]) (0.23.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepice,torch]) (2023.6.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepice,torch]) (1.22.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepice,torch]) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepice,torch]) (3.12.2)\n",
      "Collecting unidic-lite>=1.0.7\n",
      "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fugashi>=1.0\n",
      "  Downloading fugashi-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (600 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m600.9/600.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ipadic<2.0,>=1.0.0\n",
      "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting unidic>=1.0.2\n",
      "  Downloading unidic-1.1.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch<1.12,>=1.0\n",
      "  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[ja,sentencepice,torch]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[ja,sentencepice,torch]) (4.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging>=20.0->transformers[ja,sentencepice,torch]) (3.0.9)\n",
      "Collecting wasabi<1.0.0,>=0.6.0\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting plac<2.0.0,>=1.1.3\n",
      "  Downloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja,sentencepice,torch]) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja,sentencepice,torch]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja,sentencepice,torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja,sentencepice,torch]) (1.26.16)\n",
      "Building wheels for collected packages: ipadic, unidic, unidic-lite\n",
      "  Building wheel for ipadic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556721 sha256=f974b58887cd58ee44fbe2bcbedfacb4bd30cac57464be1747b132309e9fb6b4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7de1mjc8/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
      "  Building wheel for unidic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unidic: filename=unidic-1.1.0-py3-none-any.whl size=7425 sha256=987daaeb51a323b904fd7e23f99c736d1a65db737c07289b73887db6daa7d91e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7de1mjc8/wheels/7a/72/72/1f3d654c345ea69d5d51b531c90daf7ba14cc555eaf2c64ab0\n",
      "  Building wheel for unidic-lite (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658834 sha256=d187743622c717cd82a433155d05080b83c7df9ed7a05e3a5b17b27c7e216d0b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7de1mjc8/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
      "Successfully built ipadic unidic unidic-lite\n",
      "Installing collected packages: wasabi, unidic-lite, plac, ipadic, torch, fugashi, unidic\n",
      "  Attempting uninstall: wasabi\n",
      "    Found existing installation: wasabi 1.1.2\n",
      "    Uninstalling wasabi-1.1.2:\n",
      "      Successfully uninstalled wasabi-1.1.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0a0+b5021ba\n",
      "    Uninstalling torch-2.1.0a0+b5021ba:\n",
      "      Successfully uninstalled torch-2.1.0a0+b5021ba\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.0a0 requires torch==2.1.0a0+b5021ba, but you have torch 1.11.0 which is incompatible.\n",
      "torchtext 0.16.0a0 requires torch==2.1.0a0+b5021ba, but you have torch 1.11.0 which is incompatible.\n",
      "torchdata 0.7.0a0 requires torch==2.1.0a0+b5021ba, but you have torch 1.11.0 which is incompatible.\n",
      "torch-tensorrt 1.5.0.dev0 requires torch<2.2,>=2.1.dev, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fugashi-1.3.2 ipadic-1.0.0 plac-1.4.3 torch-1.11.0 unidic-1.1.0 unidic-lite-1.0.8 wasabi-0.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.10/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1489, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='24.0'),)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[ja,sentencepice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文章分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 843/843 [00:00<00:00, 5.63MB/s]\n",
      "Downloading: 100%|██████████| 1.34k/1.34k [00:00<00:00, 10.2MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 424M/424M [00:10<00:00, 42.7MB/s] \n",
      "Downloading tokenizer_config.json: 100%|██████████| 609/609 [00:00<00:00, 936kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 226k/226k [00:00<00:00, 707kB/s] \n",
      "Downloading special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 912kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'positive', 'score': 0.9993748068809509}\n"
     ]
    }
   ],
   "source": [
    "text_classification_pipeline = pipeline(\n",
    "    model = 'llm-book/bert-base-japanese-v3-marc_ja'\n",
    ")\n",
    "positive_text = '世界には言葉はわからなくても感動する音楽がある。'\n",
    "# positive_textの極性を予測\n",
    "print(text_classification_pipeline(positive_text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'negative', 'score': 0.9601457118988037}\n"
     ]
    }
   ],
   "source": [
    "# negative_textの極性を予測\n",
    "negative_text = '世界には言葉にできないほどひどい音楽がある。'\n",
    "print(text_classification_pipeline(negative_text)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自然言語推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 907/907 [00:00<00:00, 6.32MB/s]\n",
      "Downloading: 100%|██████████| 1.33k/1.33k [00:00<00:00, 10.5MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 424M/424M [00:19<00:00, 22.4MB/s] \n",
      "Downloading tokenizer_config.json: 100%|██████████| 606/606 [00:00<00:00, 3.69MB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 226k/226k [00:00<00:00, 687kB/s] \n",
      "Downloading special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 818kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'entailment', 'score': 0.9958469271659851}\n"
     ]
    }
   ],
   "source": [
    "nli_pipeline = pipeline(model='llm-book/bert-base-japanese-v3-jnli')\n",
    "text = '二人の男性がジェット機を見ています。'\n",
    "entailment_text = 'ジェット機を見ている人が二人がいます。'\n",
    "\n",
    "# textとentailment_textの論理関係を推測\n",
    "print(nli_pipeline({'text': text, 'text_pair': entailment_text}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'contradiction', 'score': 0.999154806137085}\n"
     ]
    }
   ],
   "source": [
    "contradiction_text = '二人の男性が飛んでいます。'\n",
    "print(nli_pipeline({'text': text, 'text_pair': contradiction_text}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'neutral', 'score': 0.9977497458457947}\n"
     ]
    }
   ],
   "source": [
    "neutral_text = '2人の男性が、白い飛行機を眺めています。'\n",
    "print(nli_pipeline({'text': text, 'text_pair': neutral_text}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 意味的類似度計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 796/796 [00:00<00:00, 2.16MB/s]\n",
      "Downloading: 100%|██████████| 1.30k/1.30k [00:00<00:00, 10.3MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 424M/424M [00:13<00:00, 33.8MB/s] \n",
      "Downloading tokenizer_config.json: 100%|██████████| 606/606 [00:00<00:00, 3.34MB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 226k/226k [00:00<00:00, 10.6MB/s]\n",
      "Downloading special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 917kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7349071502685547\n"
     ]
    }
   ],
   "source": [
    "text_sim_pipeline = pipeline(\n",
    "    model='llm-book/bert-base-japanese-v3-jsts',\n",
    "    function_to_apply='none'\n",
    ")\n",
    "text = '川べりでサーフボードを持った人たちがいます。'\n",
    "sim_text = 'サーファーたちが川べりに立っています。'\n",
    "# textとsim_textの類似度を計算\n",
    "result = text_sim_pipeline({'text': text, 'text_pair': sim_text})\n",
    "print(result['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028693273663520813\n"
     ]
    }
   ],
   "source": [
    "dissim_text = 'トイレの壁に黒いタオルがかけられています'\n",
    "# textとdissim_textの類似度を計算\n",
    "result = text_sim_pipeline({'text': text, 'text_pair': dissim_text})\n",
    "print(result['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8706234693527222\n"
     ]
    }
   ],
   "source": [
    "# 文埋め込みによるコサイン類似度を用いた意味的類似度\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "sim_enc_pipeline = pipeline(\n",
    "    model='llm-book/bert-base-japanese-v3-unsup-simcse-jawiki',\n",
    "    task='feature-extraction'\n",
    ")\n",
    "# textとsim_textのベクトルを獲得\n",
    "text_emb = torch.tensor(sim_enc_pipeline(text)[0][0])\n",
    "sim_emb = torch.tensor(sim_enc_pipeline(sim_text)[0][0])\n",
    "# textとsim_textの類似度を計算\n",
    "sim_pair_score = cosine_similarity(text_emb, sim_emb, dim=0)\n",
    "print(sim_pair_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4626588225364685\n"
     ]
    }
   ],
   "source": [
    "# dissim_textのエンベディング\n",
    "dissim_emb = torch.tensor(sim_enc_pipeline(dissim_text)[0][0])\n",
    "dissim_pair_score = cosine_similarity(text_emb, dissim_emb, dim=0)\n",
    "print(dissim_pair_score.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 固有表現認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.45k/1.45k [00:00<00:00, 11.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'end': None,\n",
      "  'entity_group': '人名',\n",
      "  'score': 0.99823624,\n",
      "  'start': None,\n",
      "  'word': '大谷 翔平'},\n",
      " {'end': None,\n",
      "  'entity_group': '地名',\n",
      "  'score': 0.9986874,\n",
      "  'start': None,\n",
      "  'word': '岩手 県 水沢 市'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from transformers import pipeline\n",
    "\n",
    "ner_pipeline = pipeline(\n",
    "    model='llm-book/bert-base-japanese-v3-ner-wikipedia-dataset',\n",
    "    aggregation_strategy='simple',\n",
    ")\n",
    "text = '大谷翔平は岩手県水沢市出身のプロ野球選手'\n",
    "# text中の固有表現を抽出\n",
    "pprint(ner_pipeline(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要約生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.47k/1.47k [00:00<00:00, 11.6MB/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "/usr/local/lib/python3.10/dist-packages/fused_layer_norm_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN8pybind116detail11type_casterIN3c108ArrayRefIlEEvE4loadENS_6handleEb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text2text_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm-book/t5-base-long-livedoor-news-corpus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m article \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mついに始まった３連休。テレビを見ながら過ごしている人も多いのではないだろうか？　今夜オススメなのは何と言っても、NHKスペシャル「世界を変えた男 スティーブ・ジョブズ」だ。実は知らない人も多いジョブズ氏の養子に出された生い立ちや、アップル社から一時追放されるなどの経験。そして、彼が追い求めた理想の未来とはなんだったのか、ファンならずとも気になる内容になっている。 今年、亡くなったジョブズ氏の伝記は日本でもベストセラーになっている。今後もアップル製品だけでなく、世界でのジョブズ氏の影響は大きいだろうと想像される。ジョブズ氏のことをあまり知らないという人もこの機会にぜひチェックしてみよう。 世界を変えた男　スティーブ・ジョブズ（NHKスペシャル）\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# articleの要約生成\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py:650\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# Infer the framework from the model\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;66;03m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# Will load the correct model if possible\u001b[39;00m\n\u001b[1;32m    649\u001b[0m model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 650\u001b[0m framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    662\u001b[0m load_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(model_config) \u001b[38;5;129;01min\u001b[39;00m TOKENIZER_MAPPING \u001b[38;5;129;01mor\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mtokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:257\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m     )\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 257\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    259\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:446\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    445\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2113\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2110\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(init_empty_weights())\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m-> 2113\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_no_split_modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:1477\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1475\u001b[0m encoder_config\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m encoder_config\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mT5Stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1479\u001b[0m decoder_config \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n\u001b[1;32m   1480\u001b[0m decoder_config\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:843\u001b[0m, in \u001b[0;36mT5Stack.__init__\u001b[0;34m(self, config, embed_tokens)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m embed_tokens\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mis_decoder\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 843\u001b[0m     [T5Block(config, has_relative_attention_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_layers)]\n\u001b[1;32m    844\u001b[0m )\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm \u001b[38;5;241m=\u001b[39m T5LayerNorm(config\u001b[38;5;241m.\u001b[39md_model, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mdropout_rate)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:843\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m embed_tokens\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mis_decoder\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 843\u001b[0m     [\u001b[43mT5Block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_layers)]\n\u001b[1;32m    844\u001b[0m )\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm \u001b[38;5;241m=\u001b[39m T5LayerNorm(config\u001b[38;5;241m.\u001b[39md_model, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mdropout_rate)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:627\u001b[0m, in \u001b[0;36mT5Block.__init__\u001b[0;34m(self, config, has_relative_attention_bias)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mis_decoder\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList()\n\u001b[0;32m--> 627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mappend(\u001b[43mT5LayerSelfAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mappend(T5LayerCrossAttention(config))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:558\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.__init__\u001b[0;34m(self, config, has_relative_attention_bias)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSelfAttention \u001b[38;5;241m=\u001b[39m T5Attention(config, has_relative_attention_bias\u001b[38;5;241m=\u001b[39mhas_relative_attention_bias)\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm \u001b[38;5;241m=\u001b[39m \u001b[43mT5LayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm_epsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mdropout_rate)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/apex/normalization/fused_layer_norm.py:364\u001b[0m, in \u001b[0;36mFusedRMSNorm.__init__\u001b[0;34m(self, normalized_shape, eps, elementwise_affine)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m fused_layer_norm_cuda\n\u001b[0;32m--> 364\u001b[0m fused_layer_norm_cuda \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused_layer_norm_cuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(normalized_shape, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[1;32m    367\u001b[0m     normalized_shape \u001b[38;5;241m=\u001b[39m (normalized_shape,)\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:674\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:571\u001b[0m, in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1176\u001b[0m, in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.10/dist-packages/fused_layer_norm_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN8pybind116detail11type_casterIN3c108ArrayRefIlEEvE4loadENS_6handleEb"
     ]
    }
   ],
   "source": [
    "text2text_pipeline = pipeline(\n",
    "    model=\"llm-book/t5-base-long-livedoor-news-corpus\"\n",
    ")\n",
    "article = \"ついに始まった３連休。テレビを見ながら過ごしている人も多いのではないだろうか？　今夜オススメなのは何と言っても、NHKスペシャル「世界を変えた男 スティーブ・ジョブズ」だ。実は知らない人も多いジョブズ氏の養子に出された生い立ちや、アップル社から一時追放されるなどの経験。そして、彼が追い求めた理想の未来とはなんだったのか、ファンならずとも気になる内容になっている。 今年、亡くなったジョブズ氏の伝記は日本でもベストセラーになっている。今後もアップル製品だけでなく、世界でのジョブズ氏の影響は大きいだろうと想像される。ジョブズ氏のことをあまり知らないという人もこの機会にぜひチェックしてみよう。 世界を変えた男　スティーブ・ジョブズ（NHKスペシャル）\"\n",
    "# articleの要約生成\n",
    "print(text2text_pipeline(article)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformersの使い方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 282/282 [00:00<00:00, 2.31MB/s]\n",
      "Downloading spiece.model: 100%|██████████| 765k/765k [00:00<00:00, 944kB/s] \n",
      "Downloading special_tokens_map.json: 100%|██████████| 153/153 [00:00<00:00, 1.17MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁', '今日', 'は', '天気', 'が良い', 'の', 'で']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# AutoTokenizerでトークナイザをロードする\n",
    "tokenizer = AutoTokenizer.from_pretrained('abeja/gpt2-large-japanese')\n",
    "# 入力文をトークにする\n",
    "tokenizer.tokenize('今日は天気が良いので')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 974/974 [00:00<00:00, 6.57MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 2.83G/2.83G [02:23<00:00, 21.1MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今日は天気が良いので外でお弁当を食べました。\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# 生成を行うモデルであるAutoModelForCausalLMを使ってモデルをロードする\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'abeja/gpt2-large-japanese'\n",
    ")\n",
    "# トークナイザを使ってモデルへの入力を作成する\n",
    "inputs = tokenizer('今日は天気が良いので', return_tensors='pt')\n",
    "# 後続のテキストを予測\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_length=15, # 生成する最大トークン数を15に設定\n",
    "    pad_token_id=tokenizer.pad_token_id # パディングのトークンidを指定\n",
    ")\n",
    "# generate関数の出力をテキスト変換する\n",
    "generated_text = tokenizer.decode(\n",
    "    outputs[0], skip_special_tokens=True\n",
    ")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
